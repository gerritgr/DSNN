{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f497545f-3ba5-47fb-b5b5-d9f283538344",
   "metadata": {},
   "source": [
    "# Train Baseline - DSNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4fd022-b3a6-43da-88bb-c4b7a204233b",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6adc46-970b-4980-b3f3-0aef5b3375e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import traceback\n",
    "import time\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "import networkx as nx\n",
    "import torch\n",
    "from torch_geometric.utils import to_networkx\n",
    "import numpy as np\n",
    "import scipy.linalg\n",
    "import glob\n",
    "import traceback\n",
    "\n",
    "from torch_geometric.nn.conv import x_conv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Sequential\n",
    "from torch_geometric.nn import GCN, GIN, PNA\n",
    "\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13290405-ad31-4716-9a95-12a94059f829",
   "metadata": {},
   "source": [
    "### Hypterparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1ea521-31ef-4bae-868c-07bfc4aaa4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_DIM = 64\n",
    "LAYER_NUM = 5\n",
    "DROPOUT = 0.05\n",
    "LR = 0.00001\n",
    "USE_LAYERNORM = False  #unused\n",
    "NUM_EPOCHS = 501\n",
    "USE_RESIDUAL = False  #unused\n",
    "NOISE_VAR = 0.0 #unused"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6ca98b-9e51-41cf-bc31-625abcb41507",
   "metadata": {},
   "source": [
    "### Get Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57d83a8-b16c-46fe-9b1d-3cba2051fa73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import TUDataset\n",
    "\n",
    "def get_dataset(name):\n",
    "    assert name in ['MUTAG', 'PROTEINS', 'ENZYMES', 'IMDB-BINARY']\n",
    "\n",
    "    if name == 'MUTAG':\n",
    "        dataset = TUDataset(root='data/TUDataset', name='MUTAG')\n",
    "    elif name == 'PROTEINS':\n",
    "        dataset = TUDataset(root='data/TUDataset', name='PROTEINS')\n",
    "        dataset2 = []\n",
    "        for data in dataset:\n",
    "            try:\n",
    "                data.x = data.x.reshape(-1, 3)\n",
    "            except:\n",
    "                print(data)\n",
    "                print(\"Cannot reshape data\", data.x.shape, data)\n",
    "            if data.x.numel() > 1 and data.edge_index.shape[1] > 1:\n",
    "                dataset2.append(data)\n",
    "            else:\n",
    "                print(data)\n",
    "                print(\"Illegal data\", data.x.shape, data)\n",
    "        dataset = dataset2\n",
    "    elif name == 'ENZYMES':\n",
    "        dataset = TUDataset(root='data/TUDataset', name='ENZYMES')\n",
    "    elif name == 'IMDB-BINARY':\n",
    "        dataset = TUDataset(root='data/TUDataset', name='IMDB-BINARY')\n",
    "        dataset2 = []\n",
    "        for data in dataset:\n",
    "            data.x = torch.ones(data.num_nodes).reshape(-1, 1)\n",
    "            if data.x.numel() > 1 and data.edge_index.shape[1] > 1:\n",
    "                dataset2.append(data)\n",
    "        dataset = dataset2\n",
    "\n",
    "    dataset = [d for d in dataset]\n",
    "\n",
    "    print(f\"Length of dataset: {len(dataset)}\")\n",
    "\n",
    "    random.Random(1234).shuffle(dataset)\n",
    "    split = int(0.8 * len(dataset))\n",
    "    dataset_train = dataset[:split]\n",
    "    dataset_testval = dataset[split:]\n",
    "\n",
    "    split = int(0.5 * len(dataset_testval))\n",
    "    dataset_test = dataset_testval[:split]\n",
    "    dataset_val = dataset_testval[split:]\n",
    "\n",
    "    return dataset_train, dataset_test, dataset_val\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9667753a-e239-436d-872a-0909af21a6ff",
   "metadata": {},
   "source": [
    "## NN Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdab8845-9d4b-4ed4-960b-77aee7aff7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "\n",
    "\n",
    "class GCNnet(torch.nn.Module):\n",
    "    def __init__(self, atom_dim, output_num):\n",
    "        super(GCNnet, self).__init__()\n",
    "        try:\n",
    "            self.gcn =  GCN(in_channels = atom_dim, hidden_channels = HIDDEN_DIM, out_channels=HIDDEN_DIM, num_layers=LAYER_NUM, dropout=DROPOUT)\n",
    "        except:\n",
    "            self.gcn =  GCN(in_channels = atom_dim, hidden_channels = HIDDEN_DIM, output_size=HIDDEN_DIM, num_layers=LAYER_NUM, dropout=DROPOUT)\n",
    "        self.lin = Linear(HIDDEN_DIM, output_num)\n",
    "        self.output_num = output_num\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.gcn(x, edge_index)\n",
    "        x = global_mean_pool(x, batch=torch.zeros(x.shape[0], dtype=torch.int64, device=DEVICE))  # [batch_size, hidden_channels]\n",
    "        x = self.lin(x)\n",
    "        if self.output_num == 1:\n",
    "            x = torch.sigmoid(x.flatten())\n",
    "        else:\n",
    "            x= F.softmax(x.flatten(), dim=0)\n",
    "        return x.flatten()\n",
    "\n",
    "class GINnet(torch.nn.Module):\n",
    "    def __init__(self, atom_dim, output_num):\n",
    "        super(GINnet, self).__init__()\n",
    "        self.gin =  GIN(in_channels = atom_dim, hidden_channels = HIDDEN_DIM, out_channels=HIDDEN_DIM, num_layers=LAYER_NUM, dropout=DROPOUT)\n",
    "        self.lin = Linear(HIDDEN_DIM, output_num)\n",
    "        self.output_num = output_num\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.gin(x, edge_index)\n",
    "        x = global_mean_pool(x, batch=torch.zeros(x.shape[0], dtype=torch.int64, device=DEVICE))  # [batch_size, hidden_channels]\n",
    "        x = self.lin(x)\n",
    "        if self.output_num == 1:\n",
    "            x = torch.sigmoid(x.flatten())\n",
    "        else:\n",
    "            x= F.softmax(x.flatten(), dim=0)\n",
    "        return x.flatten()\n",
    "\n",
    "    \n",
    "class PNAnet(torch.nn.Module):\n",
    "    def __init__(self, atom_dim, output_num ,deg):\n",
    "        super(PNAnet, self).__init__()\n",
    "        aggregators = ['mean', 'min', 'max', 'std']\n",
    "        scalers = ['identity', 'amplification', 'attenuation']\n",
    "        self.pna =  PNA(in_channels = atom_dim, hidden_channels = HIDDEN_DIM, out_channels=HIDDEN_DIM, num_layers=LAYER_NUM, dropout=DROPOUT,  aggregators=aggregators, scalers=scalers, deg=deg)\n",
    "        self.lin = Linear(HIDDEN_DIM, output_num)\n",
    "        self.output_num = output_num\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.pna(x, edge_index)\n",
    "        x = global_mean_pool(x, batch=torch.zeros(x.shape[0], dtype=torch.int64, device=DEVICE))  # [batch_size, hidden_channels]\n",
    "        x = self.lin(x)\n",
    "        if self.output_num == 1:\n",
    "            x = torch.sigmoid(x.flatten())\n",
    "        else:\n",
    "            x= F.softmax(x.flatten(), dim=0)\n",
    "        return x.flatten()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de1e118-fdf8-47d3-b46a-c57786b215db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    try:\n",
    "        return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        return sum(p.numel() for p in model.parameters())\n",
    "    except:\n",
    "        pass\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4c3e82-4dae-4c39-b3df-48594947b8b2",
   "metadata": {},
   "source": [
    "## Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788899bd-208a-4f43-849c-24e59bfbd55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, optimizer, model, use_softmax=False):\n",
    "  model.train()\n",
    "  loss_list = list()\n",
    "  for data in (dataset):  # Iterate in batches over the training dataset.\n",
    "    try:\n",
    "      data = data.to(DEVICE)\n",
    "      y = data.y\n",
    "      out = model(data.x, data.edge_index)  # Perform a single forward pass\n",
    "      #print(out, y)\n",
    "      if use_softmax:\n",
    "        loss = (1.0 - out[y.item()])**2\n",
    "      else:\n",
    "        loss = torch.abs(out-y)\n",
    "      if torch.isnan(loss).any():\n",
    "        continue\n",
    "      loss_list.append(loss.item())\n",
    "      loss.backward()  # Derive gradients.\n",
    "      optimizer.step()  # Update parameters based on gradients.\n",
    "      optimizer.zero_grad()  # Clear gradients.\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while running data: {e}\")\n",
    "        traceback.print_exc()\n",
    "  return np.nanmean(loss_list)\n",
    "\n",
    "\n",
    "def test(dataset, model, use_softmax = False):\n",
    "  model.eval()\n",
    "  correct = 0\n",
    "  error_list = list()\n",
    "  print_output = True\n",
    "  for data in (dataset):  # Iterate in batches over the training dataset.\n",
    "    try:\n",
    "      data = data.to(DEVICE)\n",
    "      y = data.y\n",
    "      out = model(data.x, data.edge_index)  # Perform a single forward pass.\n",
    "      if use_softmax:\n",
    "        loss = (1.0 - out[y.item()])\n",
    "        if torch.isnan(loss).any():\n",
    "          continue\n",
    "        if torch.argmax(out) == y.item():\n",
    "          correct +=1\n",
    "      else:\n",
    "        loss = torch.abs(out-y).item()\n",
    "        assert(y <= 1.0 and y>= 0.0)\n",
    "        correct +=  1 if loss < 0.5 else 0\n",
    "        print_output = False\n",
    "      error_list.append(loss)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while running data: {e}\")\n",
    "        traceback.print_exc()\n",
    "\n",
    "  return correct/len(dataset) # Derive ratio of correct predictions.\n",
    "\n",
    "\n",
    "def start_agent(name=\"HIV\", use_softmax=True, modeltype=\"GIN\"):\n",
    "  from torch_geometric.utils import degree\n",
    "  trainset, testset, valset = get_dataset(name)\n",
    "  atom_dim = trainset[0].x.shape[1]\n",
    "  output_num = 1 #trainset[0][1].numel()\n",
    "  if name == \"ENZYMES\":\n",
    "    output_num = 6\n",
    "  name = name + modeltype\n",
    "  use_softmax = output_num > 1\n",
    "  use_sigmoid = not use_softmax\n",
    "  print(\"Train\", name, 'with input dim', atom_dim, \"and output dim\", output_num)\n",
    "\n",
    "\n",
    "  max_degree = -1\n",
    "  for data in trainset:\n",
    "      d = degree(data.edge_index[1], num_nodes=data.num_nodes, dtype=torch.long)\n",
    "      max_degree = max(max_degree, int(d.max()))\n",
    "  deg = torch.zeros(max_degree + 1, dtype=torch.long)\n",
    "  for data in trainset:\n",
    "      d = degree(data.edge_index[1], num_nodes=data.num_nodes, dtype=torch.long)\n",
    "      deg += torch.bincount(d, minlength=deg.numel())\n",
    "\n",
    "  if modeltype == \"GIN\":\n",
    "    model =  GINnet(atom_dim, output_num)\n",
    "  elif modeltype == \"GCN\":\n",
    "    model =  GCNnet(atom_dim, output_num)\n",
    "  elif modeltype == \"PNA\":\n",
    "    model =  PNAnet(atom_dim, output_num, deg)\n",
    "  else:\n",
    "    assert False\n",
    "    \n",
    "  model = model.to(DEVICE)\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "  #criterion = torch.nn.CrossEntropyLoss()\n",
    "  optimizer.zero_grad()\n",
    "  best_val_acc = -1.0\n",
    "  best_test_acc = -1.0\n",
    "\n",
    "  print(\"run model on \", name, \" with num parameters: \", count_parameters(model))\n",
    "\n",
    "\n",
    "  for epoch in range(1, NUM_EPOCHS):\n",
    "      loss = train(trainset, optimizer, model, use_softmax=use_softmax)\n",
    "      mean_correct_train = test(trainset, model, use_softmax=use_softmax)\n",
    "      mean_correct_test = test(testset, model, use_softmax=use_softmax)\n",
    "      mean_correct_val = test(valset, model, use_softmax=use_softmax)\n",
    "      if mean_correct_val > best_val_acc:\n",
    "        best_val_acc = mean_correct_val\n",
    "        best_test_acc = mean_correct_test\n",
    "      if epoch % 10 == 0:\n",
    "          print(f'({name}) Epoch: {epoch:03d}, Train Loss: {loss:.4f}, Train Acc: {mean_correct_train:.4f}, Test Acc: {mean_correct_test:.4f}, Val Acc: {mean_correct_val:.4f}, Test Best Acc: {best_test_acc:.4f}')\n",
    "      try:\n",
    "        wandb.log({f\"{name}/test_acc\": mean_correct_test, f\"{name}/train_acc\": mean_correct_train, f\"{name}/val_acc\": mean_correct_val, f\"{name}/besttest_acc\": best_test_acc, f\"{name}/test_loss\": loss})\n",
    "      except:\n",
    "        pass\n",
    "  try:\n",
    "    save_src_file()\n",
    "    print(\"(finished) run model on \", name, \" with num parameters: \", count_parameters(model))\n",
    "  except:\n",
    "    pass\n",
    "  return mean_correct_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f86f31-9624-4b97-8c23-8976e051de4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_experiments():\n",
    "    for modeltype in [\"PNA\", \"GIN\", \"GCN\"]:\n",
    "        \n",
    "        try:\n",
    "            start_agent(name=\"PROTEINS\", use_softmax=False, modeltype=modeltype)\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while running start_agent for PROTEINS with modeltype {modeltype}: {e}\")\n",
    "            traceback.print_exc()\n",
    "\n",
    "        try:\n",
    "            start_agent(name=\"IMDB-BINARY\", use_softmax=False, modeltype=modeltype)\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while running start_agent for IMDB-BINARY with modeltype {modeltype}: {e}\")\n",
    "            traceback.print_exc()\n",
    "        \n",
    "        try:\n",
    "            start_agent(name=\"ENZYMES\", use_softmax=True, modeltype=modeltype)\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while running start_agent for ENZYMES with modeltype {modeltype}: {e}\")\n",
    "            traceback.print_exc()\n",
    "        \n",
    "        try:\n",
    "            start_agent(name=\"MUTAG\", use_softmax=False, modeltype=modeltype)\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while running start_agent for MUTAG with modeltype {modeltype}: {e}\")\n",
    "            traceback.print_exc()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0f4f6f-63f3-4170-a710-e970071c3c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(10):\n",
    "    start_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efd05a2-ac35-43c6-9347-a04975cd3578",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d830d9ed-dd63-42fa-bf35-de9eaf168b40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
